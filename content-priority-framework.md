# Content Priority Framework

## Content priority framework

We look at content from three perspectives to help us make decisions about it.

1. **Audience** – who is our content for?
2. **Purpose** – to what end is it published?
3. **Process** – how do we create, publish, and curate our content?

To put our content into these contexts, we ask a series of questions. The answers help us fit new content into our plans, and prioritise the content we create and manage. We ask these questions before creating content, and to assess the quality of existing content we review.

This framework of questions helps us prioritise the content we will create. But, it's a flexible approach, leaving room for collaboration and discretion.

### The questions

* Is it for our audiences?
* Does it support our purposes? 
* Is it emotionally engaging?
* Is it timely?
* How can we use it efficiently?
* What does success look like for this piece?
* What impact will it have?
* Have we already said it?
* What happens if we say no?

### Audience

We don't create or manage content for its own sake. We tell stories to people we want to influence, and we curate useful information for people who need it.

We respect our audiences, and put energy into how we communicate with them. That means we do the work of prioritising, organising, and editing so what we publish is relevant, usable, and well-crafted.

Our audiences are diverse, because our remit is wide. But, because we work to understand our users, we won't accept: "it's for everyone," as a good enough answer. Instead, address groups of people according to their needs. Some people represent more than one audience.

**We recognise these audiences:**

* Alumni
* Current students \(and family\)
* Internal
  * Institutes
  * Faculty
  * Staff
* News media
* Policy-makers
* Professionals \(seeking training\)
* Prospective students \(and family\)
* Researchers
  * Content-based partners
  * Faculty
  * Industry experts
  * Research partners

### Purposes

All content exists for a reason. Our framework of questions help us test whether content is fit for purpose. We ask questions. We make sure new content is fit for purpose \(both ours and our audiences'\). To us, purposeful content management means that anything we create has to support what we're doing as a team, a school, and a university.

**Our purposes include:**

* We establish and build emotional connections with our audiences.
* We focus on specific topics – for example: the school's _theme_ and marketing campaigns.
* We demonstrate our relevancy – for example: recent research.
* We create content to help the school generate revenue.
* We demonstrate ILR's credibility.
* We create content for our audiences, not ourselves.
* We choose the appropriate tone to carry a message and address an audience.
* We prioritise quality content over the quantity of content we could create.

### Process

Some of the answers to _how_ questions affect priority. If something is apt and aligns with our goals, but it would cost us too much to create or manage, it's still not fit for purpose.That's why we ask questions about the process before commissioning or taking on a content project.

Questions around process tend to spawn new questions, which are less about how important or appropriate content is, and more about how we will go about making, and curating it. So, our framework asks the questions that help us decide which content to prioritise and leaves room for new questions to inform us further.

#### Follow-up questions

**Impact**

* What do we want people to do with this content?
* Is there a call to action?
* How will we track or measure its effects?

**Lifecycle**

* When should this be reviewed?
* What metadata will we use for it to be used and reused?
* How can it be used in more than one way?

**Governance**

* Who needs to see it before it's published?
* Who will create it?
* Who will review it later?
* Who can delete it?

**Budget**

* Will it require freelancers to create?
* How will we promote this piece?

**Quality**

* Is it visually pleasing?
* Is it easy to read \(watch, listen-to\)?
* Does it include a third-party perspective \(or testimonial\)?

### Pre-auditing content

#### A framework of questions

What any quality-assessment tactic really boils down to is asking some questions of each item you assess.

This is the backbone of content auditing, which is usually done as its own project or piece of a project. You gather all your content, and systematically subject every content item to a rigorous framework to qualify and quantify its merit. Or, in less pompous words: you design a set of questions to ask of each piece of content.

* Is this in the right place for it to live on the site?
* Has it been reviewed recently?
* Who owns it?
* Does it fit our style guide?
* Can we delete it?

That's all content auditing is – a set of questions \(a framework\), and the collection of answers for all your content \(the audit\).

